\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Distributed scheduling of parallel tasks}
\minitoc

TODO : expliquer les besoins de taches para et le pbm des archi distribuees


\section{Scheduling parallel tasks}
The problem of scheduling parallel real-time tasks has been widely studied in the literature. In this section, we firstly analyze the existing models of parallel tasks and provide the main schedulability results associated with them. We then focus on the \emph{DAG task model} which appears to be more general than most of the other models such as the \emph{Fork-join} or the \emph{Parallel Synchronous} model and more representative of existing avionics applications.




\subsection{Parallel tasks models}
Recent advances in real-time scheduling have been trying to tackle the problem of exploiting the parallel computational power of multi and many-core processors. Researchers introduced new tasks model that contain parallelism and precedence constraints rather than purely sequential work. Several formal models of parallel tasks have been proposed. These models can be classified as having \emph{implicit} or \emph{explicit} task parallelism. The notion of implicit parallelism refers to approaches where the parallelization of the internal elements of the tasks are not decided by the scheduler. The task is considered as a black-box that is already parallelized and is manipulated by the scheduler as is. 
In contrary, models with explicit parallelism use a white-box approach. The internal dependencies of the tasks are exhibited by the model and the scheduler is in charge of respecting them.

\subsubsection{Task models with implicit parallelism}

\begin{description}
\item[Gang task model]

The \emph{Gang scheduling} approach proposed by Feitelson~\cite{Thomas1994survey, Feitelson1995} was originally introduced to leverage parallel capabilities of supercomputers. In Gang scheduling, a set of \emph{rigid} parallel tasks must be executed on $m$ identical processors. Each task is executed by several parallel threads running on a subset of the $m$ processors. Tasks are said to be \emph{rigid} because the number of their internal threads never varies.

With Gang scheduling, a taskset is modeled by the set $\tau = \{ \tau_1 , \ldots , \tau_n \}$ of sporadic tasks with $\tau_i = < O_i, v_i, C_i, D_i, T_i >$ a parallel task characterized by:
the initial offset $O_i$;
the number of threads $v_i$;
the WCET  $C_i$;
the minimum inter-arrival time $T_i$;
and the relative deadline $D_i$.

The WCET $C_i$ of a Gang task is the total duration spanning from the beginning of the first starting thread to the end of the last ending thread.

In \cite{Kato2009}, Kato \etal proposed the \emph{Gang-EDF} preemptive scheduling algorithm which applies the \emph{Earliest Deadline First} policy to Gang tasksets. The authors also provide a sufficient schedulability condition for Gang EDF. More recently, Goossens \etal provided in~\cite{Goossens2010_RTNS} an exact schedulability test for Fixed Task Priority assignment of Gang tasksets.

\item[Work-limited Parallelism task model]
Similarly to Gang scheduling, the approaches based on \emph{Work-limited Parallelism} consider intra-task parallelism. A taskset is modeled as $\tau = \{ \tau_1 , \ldots , \tau_n \}$  with $\tau_i = < C_i, T_i, \Gamma_i>$ a parallel task characterized by:
        its \emph{sequential} WCET $C_i$;
its minimum inter-arrival time $T_i$;
        and $\Gamma_i = < \gamma_{i,1} , \ldots , \gamma_{i,m} >$ a $m$-tuple of real numbers with $m$ the number of processors. With Work-limited parallelism, the parameter $\Gamma_i$ represents the degree of parallelism of $\tau_i$. A job of $\tau_i$ running during $t$ units of time on $k$ processors is assumed to have completed $\gamma_{i,k} \times t$ units of execution. The WCET $C_i$ represents the total amount of work to be done.

In~\cite{Collette2007, Collette2008} Colette \etal proved that the feasibility problem can be decided in linear time-complexity in function of the number of tasks for a fixed number of processors. Moreover, they provided a theoretically optimal scheduling algorithm for Work-limited Parallel tasks and an exact feasibility utilization bound.
\end{description}

\subsubsection{Task models with explicit parallelism}
\begin{description}
\item[Fork-join task model]
    The \emph{Fork-join} model is a classical paradigm for parallel tasks. Its is notably used in OpenMP~\cite{OpenMP} and Java~\cite{Lea2000}. As depicted in Figure~\ref{fig_stateOfTheArt_2_forkjoin}, a Fork-join tasks start its execution with sequential code in a main thread. Once a \emph{fork} construct is reached, several threads run in parallel  until a synchronization point materialized by a \emph{join} construct. After a join, parallel thread stops and leave the master thread alone running sequential code again. The complete execution of a Fork-join task can require a series of parallel and sequential executions. 
        
        Lakshmanan \etal introduced real-time considerations about Fork-join model in~\cite{Lakshmanan2010}. Counter-intuitively, they argued that the internal parallelism of Fork-join tasks may, in the worst case, narrow the resource utilization and be a problem regarding feasibility. They proposed a stretching algorithm to tackle the problem. The algorithm maximizes the amount of sequential code. It limitates the parallelization to situations where pure sequential code would not allow to meet the task's deadline.


\begin{figure}
    \centering
    \input{imgs/tex/stateOfTheArt_2_forkjoin.tex}
    \caption{Example of a Fork-join task $\tau_1$ with two parallel sub-sequences of three threads each}
    \label{fig_stateOfTheArt_2_forkjoin}
\end{figure}

\item[Parallel Synchronous task model]
    The \emph{Parallel Synchronous task model} was introduced by Saifullah \etal in~\cite{Saifullah2011}. As depicted in Figure~\ref{fig_stateOfTheArt_2_parallelSync}, a synchronous parallel task consists in a sequence of parallel \emph{segments} during which several threads run in parallel. The number of threads per segment is fixed a priori but is not necessarily the same for all segments. More precisely, a taskset is modeled as $\tau = \{ \tau_1 , \ldots , \tau_n \}$  where each task $\tau_i$ is a sequence of $s_i$ segments. The $j$-th segment of task $\tau_i$ is defined by the tuple $<e_{i,j}, m_{i,j}>$ where $e_{i,j}$ is the timing requirement (the \emph{implicit} deadline) of the segment and $m_{i,j}$ is the number of threads in the segment. In~\cite{Saifullah2011}, the authors proposed a task decomposition transforming a Parallel Synchronous task into a set of sequential tasks. Each sequential task is assigned an offset and a deadline and represents one thread of one segments. By doing so, the task set can be managed with classical multi-core scheduling algorithms such a Global EDF.

\begin{figure}
    \centering
    \input{imgs/tex/stateOfTheArt_2_parallelSync.tex}
    \caption{Example of a Parallel Synchronous task $\tau_1$ with three parallel segments}
    \label{fig_stateOfTheArt_2_parallelSync}
\end{figure}



\item[DAG model]
    The \emph{Directed Acyclic Graph} (or \emph{DAG}) model if often considered as the most general model for tasks with explicit parallelism. Indeed, both the Fork-join and the Parallel Synchronous models can be seen as special cases of the DAG model. A periodic DAG task is modeled as a set of sub-tasks whose execution order is constrained by precedence relations. A real-time DAG task is periodically activated and must complete before an implicit deadline. Usually, all sub-tasks are activated with their parent task and temporally constrained with the same deadline. More precisely, a taskset is modeled as $\tau = \{ \tau_1 , \ldots , \tau_n \}$ with $\tau_i = <S_i, P_i, T_i>$ a DAG task characterized by:
        $S_i = \{ \tau_i^1 , \ldots , \tau_i^{n_i} \}$ the set of sub-tasks, 
        $P_i \subset S_i \times S_i$ the set of precedence relations between the sub-tasks and 
        $T_i$ the period of the task. Each sub-task $\tau_i^j$ is associated with its WCET $C_i^j$. An example of DAG task is depicted in Figure~\ref{fig_stateOfTheArt_2_DAGTask}

\begin{figure}
    \centering
    \input{imgs/tex/stateOfTheArt_2_DAGTask.tex}
    \caption{Example of a DAG task $\tau_1$ with 10 sub-tasks}
    \label{fig_stateOfTheArt_2_DAGTask}
\end{figure}
\end{description}

Since DAGs cover the other models of parallel tasks, we will focus our analysis of the existing parallel task scheduling techniques only to those which consider DAG tasks. We will firstly introduce classical DAG notions to ease the understanding of the following sections. Then, we will study the founding contributions on DAG scheduling on mono-core processors before analyzing the extensions that were made more recently for multi-core chips.

\subsection{Scheduling of DAG tasks}
\subsubsection{DAG notions}
DAGs inherit from all the theoretical foundations of Graph Theory. Manipulation of DAGs are commonly achieved using classical mathematical notions on directed graphs. For commodity, we remind some of these notions and precise the notations below.

In Graph Theory, a DAG is defined as $G = <N,E>$ where $N$ are the \emph{nodes}\footnote{Nodes are often denoted \emph{vertices} in the literature} of the Graph and $E \subset N\times N$ is a set of ordered pairs of nodes representing the \emph{edges}. $N$ and $E$ are respectively equivalent to $S_i$ and $P_i$ in the DAG task model.

The \emph{parents} of a node $n_i \in N$  are the set of nodes connected to $n_i$ by an edge and preceding it in the ordering. More precisely, $n_j$ is a parent of $n_i$ if and only if $\exists <n_j, n_i> \in E$. Similarly, the \emph{children} of $n_i$ are the set of nodes connected to $n_i$ by an edge and following it in the ordering. More precisely, $n_j$ is a child of $n_i$ if and only if $\exists <n_i, n_j> \in E$.

\begin{example}[Parents and children in DAGs]
    The parents of the sub-task $\tau_1^7$ in Figure~\ref{fig_stateOfTheArt_2_DAGTask} are $\tau_1^3$ and $\tau_1^5$. Its children are $\tau_1^8$ and $\tau_1^9$.
\end{example}

$e_1 = <n_1, n_2> \in E , \ldots <n_{k-1}, n_k> \in E$.

The \emph{predecessors} of a node extends the notion of parents recursively. $n_j$ if a predecessor of $n_i$ if and only if there is a path linking $n_j$ to $n_i$. Similarly, the \emph{successors} of a node extend the notion of children recursively. $n_j$ is a successor of $n_i$ if and only if there is a path linking $n_i$ to $n_j$.

\begin{example}[Predecessors and successors in DAGs]
    The predecessors of the sub-task $\tau_1^7$ in Figure~\ref{fig_stateOfTheArt_2_DAGTask} are $\tau_1^1, \tau_1^2, \tau_1^3$ and $\tau_1^5$. Its successors are $\tau_1^8, \tau_1^9$ and $\tau_1^{10}$.
\end{example}

A \emph{path} is a sequence of adjacent nodes defined as $p = <n_1 , \ldots , n_k>$. $p$ connects $n_1$ to $n_k$ if and only if subsequent nodes are connected by edges in $E$, i.e, 

The \emph{Critical Path} (or $CP$) in a DAG is its longest path. The length a path in a DAG task model is equal to the sum the WCETs of sub-tasks composing it. The $CP$ of a DAG task represents the shortest execution time of the task when parallelized. The ratio between the WCET of the task and the length of its CP is defined as the \emph{maximum speedup} $M$.

\begin{displaymath}
    M(\tau_i) = \dfrac{ \underset{\tau_i^j \in S_i}{\sum} C_i^j}{ \underset{ \tau_i^k \in CP(\tau_i) }{\sum} C_i^k}
\end{displaymath}

\begin{example}[CP and speedup]
    Assuming that odd sub-tasks of Figure~\ref{fig_stateOfTheArt_2_DAGTask} 
    ($\tau_1^1 , \tau_1^3, \tau_1^5, \tau_1^7$ and $\tau_1^9$) have a WCET of 5 and the even sub-tasks 
    ($\tau_1^2 , \tau_1^4, \tau_1^6, \tau_1^8$ and $\tau_1^{10}$) have a WCET of 3, the critical path of the task is $CP(\tau_1) = <\tau_1^1 , \tau_1^3, \tau_1^7, \tau_1^9 , \tau_1^{10}>$ with a length of 23. The total WCET of $\tau_1$ is 40. Thus, $M(\tau_1) = 40/23 \simeq 1.74$. 
\end{example}

DAG nodes can be sorted in a \emph{topological order} to produce a linear sequence of sub-tasks that respect the precedence constraint.

\begin{example}[Topological order]
    A topological order of the DAG of Figure~\ref{fig_stateOfTheArt_2_DAGTask} is:
    $$< \tau_1^1 , \tau_1^2 , \tau_1^4 , \tau_1^5, \tau_1^3 , \tau_1^7 , \tau_1^6 , \tau_1^8 , \tau_1^9 , \tau_1^{10} >$$
\end{example}

Topological sorting is of importance since its provides a correct monocore schedule of a DAG task. Algorithms are known to produce topological ordering of any DAG in linear time.

\subsubsection{Real-time scheduling of DAG tasks}
Chetto \etal presented in~\cite{Chetto1990} an approach to schedule independent periodic sequential tasks together with sporadic groups of DAG tasks on \emph{mono-core} processors. Chetto \etal proposed to modify the timing parameters of the constrained sub-tasks to transform them in an equivalent set of independent tasks that can be scheduled with classical algorithms such as EDF. The idea is to assign each sub-task in the DAG a modified release date based on the finish time of its parents and a modified deadline based on the deadline of its children. Chetto \etal proved the optimality of this algorithm in the sense that the original dependent task set is schedulable if and only if the modified relaxed taskset is schedulable.



However, the problem of scheduling DAG tasks on \emph{multi-core} processors in a preemptive manner has been shown by Ullman to be strongly NP-Hard~\cite{Ullman1975}. In~\cite{Baruah2012_RTSS}, Baruah \etal studied the problem of scheduling sporadic DAG tasks with arbitrary deadlines on such targets. They have shown that situations where DAG jobs are activated at their maximum frequency (meaning that the duration between two job activations is always the minimum) counter-intuitively do not systematically correspond to the worst-case scenario. In addition, they demonstrated that solutions for the scheduling problem can be efficiently approximated using EDF.

While Baruah \etal focused on scheduling a single DAG task in~\cite{Baruah2012_RTSS}, Li \etal~\cite{Li13} extended their work to several tasks. They proposed an approached based on global preemptive scheduling of sporadic implicit-deadline tasksets on homogeneous multi-core processors using Global-EDF (or \emph{GEDF}). In~\cite{Bonifaci2013}, Bonifaci \etal addressed a similar problem and extended their result by showing that global DM scheduling provided a better resource augmentation bound than GEDF.


In~\cite{Qamhieh2013, Qamhieh2014}, Qamieh \etal emphasized that the authors of~\cite{Baruah2012_RTSS,Li13,Bonifaci2013} were only considering \emph{general} timing parameters of DAG tasks such as their total WCET or the length of their critical path. They argued that schedulability analysis of DAG tasks could be improved by taking into account more information about the timing parameters of sub-tasks and the constraints on their execution flow.
They proposed two approaches denoted as the \emph{Model Transformation} and the \emph{Direct Scheduling} techniques for scheduling DAG tasks on multi-core processors. The idea of the Model Transformation is to convert each DAG task into a set of independent sequential tasks by adding extra timing parameters such as intermediate offsets and deadlines to sub-tasks. By doing so, the resulting modified taskset becomes a classical model of independent real-time tasks that can be scheduled using state-of-the-art algorithms.
Yet, the Model Transformation technique has the drawback of losing some of the DAG model's generality and to become more restricted because of the extra timing parameters. To overcome this issue, the Direct Scheduling approach does not aim at modifying the model to re-use existing algorithms but rather to apply scheduling techniques directly on the DAG models without changing their characteristics. Globally, the idea of the \emph{DAG stretching algorithm} that implements the Direct Scheduling approach is to append as many non-critical sub-tasks as possible to the critical path to form one sequential thread with a maximum utilization. By doing so, the number of sub-tasks that are executed in parallel with this main thread is minimized, thus simplifying the scheduling. In~\cite{Qamhieh2014}, Qamieh \etal showed in simulation with syntetic tasksets that, despite the goal of minimizing the parallelism during execution, this approach had better schedulability ratios than existing techniques for scheduling DAG tasks. Yet, it can be argued that minimizing the slack of the master thread increases the risk of suffering deadline misses if the WCET estimation of a sub-task was inaccurate.


\subsubsection{Makespan-optimization techniques}
Outside from the real-time community, the problem of scheduling dependent tasksets on multi-core processors has been thourougly studied. As a main difference, the tasks models that are commonly considered do not necessarily represent periodic tasks or include any deadline constraints. In general, the approaches rather strive for reducing the total completion time of a DAG task, commonly refered to as the \emph{makespan-optimization} problem.

In~\cite{Kwok1999}, Kwok and Ahmad overviewed the plethora of static scheduling algorithms for allocating non-periodic DAG tasks on multi-core processor. Given the NP-completeness of the scheduling problem~\cite{Garey1979}, most of the proposed solutions consider heuristics based on the \emph{list scheduling} technique~\cite{Adam1974,Ahmad1996,Casavant1988,ElRewini1994,Gerasoulis1992,Shirazi1990,McCreary1994,Yang1988,Coffman1976}. The idea is to keep a priority queue of the sub-tasks that can be scheduled and to iteratively pick $\tau_i^j$ the first element of the queue, place it the core on which it can start the earliest and add to the queue the children sub-tasks of $\tau_i^j$. Usually, the scheduling algorithms vary essentially in the way of assigning priorities to sub-tasks. 


Some algorithm assign static priorities to sub-tasks such as \emph{HLF} (or \emph{Highest Level First})~\cite{Coffman1976}, \emph{LPT} (or \emph{Longest Processing Time})~\cite{Friesen1987} and \emph{CP} (or \emph{Critical Path})~\cite{graham1979}. More recent approaches usually assign priorities \emph{dynamically}. In these approaches, the priorities are not fixed a priori and all priorities in the scheduling queue are re-computed every time a sub-task is appended to it.  

Two common timing attributes for assigning priorities to sub-tasks are the \emph{b-level} and the \emph{t-level} defined as:
\begin{description}
    \item[t-level] : the t-level of a sub-task $\tau_i^j$ is the longest path from an entry node to $\tau_i^j$. The t-level can be seen as the earliest start time of a sub-task.
    \item[b-level] : the b-level of a sub-task $\tau_i^j$ is the longest path from $\tau_i^j$ to an exit node. All b-levels are upper bounded by the length of the Critical Path of the DAG.
\end{description}

These timing attributes are used in many popular list-scheduling algorithms such as the \emph{Highest Level First with Estimated Times} (or \emph{HLFET}) algorithm~\cite{Adam1974}, the \emph{Insertion Scheduling Heuristic} (or \emph{ISH})~\cite{Kruatrachue1987} or the \emph{Modified Critical Path} (or \emph{MPC}) algorithm~\cite{Wu1990}.

\begin{example}[HLFET algorithm]
    The HLFET algorithm goes as follows:
    \begin{enumerate}
        \item Compute the \emph{b-level} of each sub-tasks
        \item Put ready sub-tasks into the priority queue. Highest priority is given to sub-tasks with largest b-level.
        \item Schedule the sub-task with highest priority to the core on which it can start the earliest.
        \item Update the scheduling queue with the sub-tasks that are now ready.
        \item Repeat 3 and 4 until all sub-tasks are scheduled.
    \end{enumerate}
\end{example}


Overall, all those makespan-oriented scheduling algorithms consider single task problems whithout real-time constraint. Many heurisitcs have been proposed, mostly using a list-scheduling approach, in order to assign sub-tasks to cores. Yet, applying such approaches is impossible in a hard-real time context without profound modifications of the models and algorithms to manage multiple parallel tasks with deadline constraints.





\section{Mapping on distributed architectures}
\subsection{Mapping on the \mppalong}
Giannopoulou \cite{Giannopoulou2013_EMSOFT} \cite{Giannopoulou2015}

In~\cite{Becker16}, Becker \etal proposed a method to schedule tasks inside a single cluster of the \mppalong. They proposed an ILP formulation of the mapping problem together with sub-optimal heuristics enabling the approach to scale from small programs to actual industrial-sized applications. The authors eliminated inter-core interferences during execution thanks to privatization of local memory banks to each core and assumed a \emph{read-execute-write} semantics of the application similarly to the AER execution model. They consider only automotive applications following an AUTOSAR model where each task $\tau_i $(also denoted as a \emph{Runnable}) is a sequential piece of code characterized by a period $T_i$ , a WCET $C_i$ and memory footprint $S_i$. Using the read-execute-write semantics, the WCET of a task is decomposed into three phases $C_i = C_i^{rd} + C_i^{ex} +C_i^{wr}$:
\begin{itemize}
    \item the read phase of duration $C_i^{rd}$ during which the code and data of the runnable are copied from the external RAM into a local cluster's memory bank;
    \item the execution phase of duration $C_i^{ex}$ during which the code of the task is executed by a PE;
    \item and the write phase of duration $C_i^{wr}$ during which the data produced by the task are commited to the external RAM.
\end{itemize}

In~\cite{Becker16}, the authors modeled each task by three jobs corresponding to the three phases. Then, they proposed different solutions to the problem of assigning execution jobs to cores and read and write jobs to non-overlapping time frames. In addition, communication between tasks are ensured using a dedicated local memory bank which statically stores all the data that will be exchanged. In doing so, the communication model of the application remains implicit and the  applicability of the approach is thus limited to single-cluster applications. In addition, bounds on $C_i^{rd}$ and $C_i^{wr}$ are computed while assuming no competing accesses to the external RAM. 



\subsection{Mapping on other many-core architectures}
Prelude
Rosace~\cite{Pagetti2014}
Wolfgang~\cite{PuffitschNP15}
Carle~\cite{Carle2014}

\subsection{Core and network co-scheduling}
Craciunas~\cite{Craciunas2016}

\section{Summary}

\clearpage
\subbiblio
\end{document}
